<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>kemu1</title>
    <link href="/blog/2023/06/01/kemu1/"/>
    <url>/blog/2023/06/01/kemu1/</url>
    
    <content type="html"><![CDATA[<div class="note note-primary">            <p>Iâ€™m a nested list :D<br>94/100 ä¸€é -&gt; PASS</p>          </div><p>Sources helped me prep kemu1 in Shanghai, China (C2 licence in China).<br>å¤§éƒ¨åˆ†é™¤äº†æ ‡å¿—çš„è€ƒç‚¹è¿™è¾¹æ€»ç»“çš„å¾ˆå…¨</p><ul><li><a href="https://zhuanlan.zhihu.com/p/556065386">https://zhuanlan.zhihu.com/p/556065386</a></li></ul><p>äº¤é€šæ ‡å¿—çš„ sourceï¼ˆå…¨çš„</p><ul><li><a href="https://www.jiakaobaodian.com/sign/2/">https://www.jiakaobaodian.com/sign/2/</a></li></ul><p>æˆ‘ç²¾ç®€ 500 é“ï¼ˆä¸€å¼€å§‹åˆ·è¦å¤šç†è§£ç†è§£ï¼Œä¼šæ¯”è¾ƒæ…¢ï¼‰å®Œï¼Œç„¶åæ¨¡è€ƒäº† 10 æ¬¡ï¼ˆä¸‰å¤©æ¯å¤© 3 å¥—ï¼Œç„¶åæ€»ç»“æ€»ç»“ï¼Œåé¢å¾ˆå¤šé¢˜ç›®é‡å¤çš„å¤šäº†å°±å˜å¿«å¾ˆå¤šï¼‰ã€‚ä¸Šæµ·é¢˜å’Œæ–°è§„é¢˜å¤šçœ‹ï¼ˆæˆ‘æŠŠä¸Šæµ·é¢˜åˆ·å®Œäº†ï¼Œæ²¡å¤šå°‘é“ï¼Œæ¯”è¾ƒ trickyï¼‰</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Intro to Learning Theory</title>
    <link href="/blog/2023/05/07/learning-theory/"/>
    <url>/blog/2023/05/07/learning-theory/</url>
    
    <content type="html"><![CDATA[<h1>CS 189 Learning Theory blog</h1><div class="note note-primary">            <p>This is a blog post for CS 189 lecture on Learning Theory, contents are organized in the flow of the lecture. This blog isnâ€™t the final version yet.</p>          </div><p>A range space is a pair $P$, $H$:</p><p>$P$ is <strong>set of all possible test/training points</strong> (can be infinite)</p><p>$H$ is a <strong>hypothesis class</strong> (set the boundary of legal classifiers), a set of hypotheses (classifiers)</p><ul><li>e.g. all the linear classifiers</li></ul><p>Suppose all training pts &amp; test pts are drawn <em>independently</em> from same prob. distribution $\mathcal D$ defined on domain $P$</p><p>$h\in \mathcal H$ be a hypothesis (a classifier), h predicts a pt x is in class C if $x\in h$</p><p>Risk (generalization error) $R(h)$ of $h$ is the probability that $h$ misclassifies a random pt $x$ drawn from $\mathcal D$ (i.e. the prob that $x\in C$ but $\notin h$) â† essentially test error</p><ul><li>risk is the average test error for test points drawn randomly from $\mathcal D$ (ä½†æˆ‘ä»¬ä¸€èˆ¬æ˜¯ä¸€ä¸ª subset of the theoretical entire set of $\mathcal D$, so test error sometimes is high, sometimes is low).</li></ul><p>Notation:</p><p>Let $X\subseteq P$ be a set of $n$ training pts drawn from $\mathcal D$</p><p>Empirical risk (training error) $\hat R(h)$ is % of $X$ misclassified by $h$</p><p>$h$ misclassfies each training pt w/ prob. $R(h)$, so total misclassified has a binomial distributio.</p><p>$P(|\hat R(h)-R(h)|&gt;\epsilon) \le2e^{-2\epsilon^2n}$</p><ul><li>when n is very large, the probability gets smaller.</li></ul><p>Idea for learning algorithm: choose $\hat h\in H$ that minimizes $\hat R(\hat h)$ â† empirical risk minimization</p><p>Problem: if too many hypotheses, some $h$ with high $R(h)$ will get lucky and have very low $\hat R(h)$</p><ul><li>we can have so many hypotheses that some of them just get lucky and score far lower training error than their actual risk.<br>â†’ This is overfitting</li></ul><p>Dichotomies</p><ul><li>a dichotomy of $X$ is $X \cap h$, where $h\in H$<ul><li>picks out the training points that $h$ predicts are in class $C$</li><li>e.g. for $n$ training points, there could be up to $2^n$ dichotomies.</li><li>$\hat R(\hat h) = 0$ even if every $h\in H$ has high risk</li><li>we simply overfits</li></ul></li></ul><p>We limit to have a constant $\prod$ dichotomies,</p><p>$P(\text{at least one dichotomy has } |\hat R - R|\ge\epsilon)\le\delta$</p><ul><li>$\delta = 2\prod e^{-2\epsilon^2n}$</li><li>Hence with prob. $\ge 1-\delta$ for every $h\in H$</li><li>$\downarrow$ complement of the above inequality</li><li>$|\hat R(h) - R(h)| \le \epsilon = \sqrt{\frac 1{2n}ln\frac{2\prod}{\delta}}$</li></ul><div class="note note-info">            <p>ğŸ’¡Lesson: the smaller we make $\prod$, the number of dichotomies, and larger the n, the number of training points, the more accurately the training error will approximate how well the classifier performs on test data.</p>          </div><p>Smaller $\prod$ means weâ€™re less likely to overfit, we have less variance, but more bias. But it doesnâ€™t mean that risk is small.</p><ul><li>Goal: we want a H that fits the data well and doesnâ€™t produce many dichotomies.</li></ul><p>Let $h^* \in H$ minimizes $R(h^*)$: â€œbestâ€ classifier</p><p>Let $\hat h\in H$ minimizes $\hat R(\hat h)$; the classifier we learn, with prob $\ge 1-\delta$, our chosen $\hat h$ has nearly optimal risk:</p><blockquote><p>Note: we still choose the best classifier $\hat h$ that minimizes the empirical risk. We donâ€™t know the actual $h^*$ since we have no means to know it. But if $\prod$ is small and $n$ is large, the hypothesis $\hat h$ we have chosen is probably nearly as good as $h^{*}$.</p></blockquote><p>We have the following inequalities:</p><p>$R(\hat h) \le \hat R(\hat h) +\epsilon$</p><ul><li>got from previous inequalities</li></ul><p>since $\hat R$ is lowest on classifiers trained on training data, itâ€™s not the lowest on the theoretical optimal $\hat h$.</p><p>Then, using the previous inequality again, we have<br>$\hat R (h^{*})+ \epsilon \le R(h^*) + 2\epsilon$</p><p>To sum up,</p><p><img src="https://s2.loli.net/2023/05/08/gYk8ltA9ZPvf7nM.png" alt=""></p><p>Sample complexity: the # of training pts needed to achieve this $\epsilon$ with prob $\ge 1-\epsilon$</p>]]></content>
    
    
    
    <tags>
      
      <tag>ml</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI generated images literature review</title>
    <link href="/blog/2023/05/06/aigc-literature-review/"/>
    <url>/blog/2023/05/06/aigc-literature-review/</url>
    
    <content type="html"><![CDATA[<h1><a href="https://bold-tortellini-108.notion.site/Literature-Review-AI-61a89e4b56fc4a4e899aa387c6b05c91">Notion Blog Post Link &lt;- Click Here!</a></h1><div class="note note-warning">            <p>Checkout the Notion Blog in the Title!</p>          </div><p><img src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/ai_art_on_shutterstock_hero.jpg" alt=""></p>]]></content>
    
    
    
    <tags>
      
      <tag>aigc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>latex equation align</title>
    <link href="/blog/2023/04/30/latex-equation-align/"/>
    <url>/blog/2023/04/30/latex-equation-align/</url>
    
    <content type="html"><![CDATA[<h1>latex equation align</h1><div class="note note-primary">            <p>Daily tip of new latex skills.</p>          </div><p>I was search for ways to align multiple parts of an equation, and found this <a href="https://tex.stackexchange.com/questions/49014/aligning-equations-with-text-with-alignat">post</a> on stackexchange.</p><p>The <code>align</code> environment is the vanilla way to align equations, and the <code>&amp;</code> symbol is used to specify the point of alignment.</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;align&#125;<br>    a <span class="hljs-built_in">&amp;</span>= b + c <span class="hljs-keyword">\\</span><br>      <span class="hljs-built_in">&amp;</span>= d + e<br><span class="hljs-keyword">\end</span>&#123;align&#125;<br></code></pre></td></tr></table></figure><p>$$<br>\begin{align}<br>a &amp;= b + c\\<br>&amp;= d + e<br>\end{align}<br>$$</p><p>To specify more than one point of alignment, use the <code>alignat</code> environment. The first argument is the number of points of alignment, and the second argument is the number of columns in the equation.</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;alignat*&#125;&#123;3&#125;<br><span class="hljs-built_in">&amp;</span> m   <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\text</span>&#123;mÃ³dulo&#125;            <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> m&gt;0<span class="hljs-keyword">\\</span><br><span class="hljs-built_in">&amp;</span> a   <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\text</span>&#123;multiplicador&#125;     <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> 0&lt;a&lt;m<span class="hljs-keyword">\\</span><br><span class="hljs-built_in">&amp;</span> c   <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\text</span>&#123;constante aditiva&#125; <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> 0<span class="hljs-keyword">\leq</span> c&lt;m<span class="hljs-keyword">\\</span><br><span class="hljs-built_in">&amp;</span> x<span class="hljs-built_in">_</span>0 <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\text</span>&#123;valor inicial&#125;     <span class="hljs-keyword">\quad</span> <span class="hljs-built_in">&amp;</span><span class="hljs-built_in">&amp;</span> 0<span class="hljs-keyword">\leq</span> x<span class="hljs-built_in">_</span>0 &lt;m<br><span class="hljs-keyword">\end</span>&#123;alignat*&#125;<br></code></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2023/05/08/uw4kp26UsrPRieX.png" alt="latex.png"></p><p>Additionally, thereâ€™s a discussion of whatâ€™s the difference between <code>&amp;</code> and <code>&amp;&amp;</code> in this thread, feel free to checkout this for more information!</p><p><a href="https://tex.stackexchange.com/questions/159723/what-does-a-double-ampersand-mean-in-latex">What does a double ampersand (&amp;&amp;) mean in LaTeX?</a></p><div class="note note-secondary">            <p>Thanks for reading, if you have any questions/suggestions, please leave a comment below.</p>          </div>]]></content>
    
    
    
    <tags>
      
      <tag>latex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Build a deep-learning workstation</title>
    <link href="/blog/2023/04/23/deep-learning-workstation/"/>
    <url>/blog/2023/04/23/deep-learning-workstation/</url>
    
    <content type="html"><![CDATA[<h1>Build a deep-learning workstation</h1><!-- toc --><div class="note note-primary">            <p><strong>Motivation</strong>:<br>not rely on any labâ€™s computing resource, <strong>learn &amp; experiment with</strong> public deep learning repos. I canâ€™t replicate the results on my XPS 15 RTX 3050TI 4GB GPU, which forces me to look at other resources. Looking at the pricing and setup needed to work with cloud computing, I found better returns by building my own deep-learning workstation. Trying and replicating the results of these repos are absolutely important for learning and creativity. Crazy GPU Speed isnâ€™t my focus at the moment, but large GPU mem is the key. 3060 seems to be the most price efficient one in the market at this point.</p>          </div><p><img src="https://s2.loli.net/2023/05/08/kfaZXiT4WUlRFr7.jpg" alt=""><br><img src="https://s2.loli.net/2023/05/08/NQOLasbGrAmSy5u.jpg" alt=""></p><h2 id="Videos-referenced">Videos referenced:</h2><p>Which GPU to choose for deep learning?</p><p><a href="https://www.youtube.com/watch?v=F1ythHjdWI0">How to Choose an NVIDIA GPU for Deep Learning in 2023: Ada, Ampere, GeForce, NVIDIA RTX Compared</a></p><p><a href="https://www.youtube.com/watch?v=OWvy-fCWTBQ">How to Build a Deep Learning Machine - Everything You Need To Know</a></p><p><a href="https://www.youtube.com/watch?v=XIHG11EzB28">How to Assemble a Deep Learning Machine - Full Process | Part 2</a></p><p><a href="https://www.youtube.com/watch?v=ttxtV966jyQ">How To Install CUDA, cuDNN, Ubuntu, Miniconda | ML Software Stack | Part 3/3</a></p><h3 id="Optional-Article-references">(Optional) Article references</h3><p><a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/#">which-gpu-for-deep-learning</a></p><p><a href="https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">deep-learning-hardware-guide</a></p><h2 id="Specs-of-my-machine-for-replication-purpose">Specs of my machine (for replication purpose):</h2><div class="note note-info">            <p><strong>Price</strong>: $924.99<br><strong>CPU</strong>: AMD Ryzen 7-5800<br><strong>Memory:</strong> 16GB<br><strong>GPU:</strong> NVIDIA GeForce RTX 3060 12GB<br><strong>SSD:</strong> 1TB (Samsung 970 evo plus) +$69.99</p>          </div><p><a href="https://www.bestbuy.com/site/lenovo-legion-tower-5-amd-gaming-desktop-amd-ryzen-7-5800-16gb-memory-nvidia-geforce-rtx-3060-256gb-ssd-1tb-hdd-raven-black/6501812.p?skuId=6501812"></a></p><div class="note note-info">            <p>ğŸ”— Follow this video for in-depth environment installation instruction <a href="https://www.youtube.com/watch?v=ttxtV966jyQ">How To Install CUDA, cuDNN, Ubuntu, Miniconda | ML Software Stack | Part 3/3</a></p>          </div><div class="note note-info">            <p>ğŸ“˜ Official documentation referenced from <code>How To Install CUDA, cuDNN, Ubuntu, Miniconda | ML Software Stack | Part 3/3</code></p>          </div><ol><li><p>âœ… <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">Ubuntu installation</a></p></li><li><p>âœ… <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">CUDA installation</a></p></li><li><p>âœ… <a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html">cuDNN installation</a></p></li></ol><h1>SSH-ing</h1><h3 id="Step-1-Step-up-ssh-from-remote-laptops-e-g-mac-windows-to-Ubuntu-within-LAN">Step 1: Step up ssh from remote laptops (e.g. mac/windows) to Ubuntu <em>within LAN</em></h3><p><a href="https://www.youtube.com/watch?v=Wlmne44M6fQ&amp;t=1s">How to enable SSH on Linux Ubuntu (Easy step by step guide)</a></p><h3 id="Step-2-Step-up-ssh-port-forwarding-to-connect-from-any-network-through-remote-laptops-e-g-mac-windows-to-Ubuntu">Step 2: Step up ssh port forwarding to connect from any network through remote laptops (e.g. mac/windows) to Ubuntu</h3><p><a href="https://www.zhihu.com/zvideo/1621515254902521856">windows ç³»ç»Ÿå¦‚ä½•é€šè¿‡ ssh è¿œç¨‹è¿æ¥ linuxï¼Ÿ - çŸ¥ä¹</a></p><p><a href="https://www.cpolar.com/">cpolar - å®‰å…¨çš„å†…ç½‘ç©¿é€å·¥å…·</a></p><blockquote><p>I used the free account that fulfills my personal usage and need. Works perfectly at the moment. There can be other cleaner approaches, but I havenâ€™t find such one. Please send me a message if you found one.</p></blockquote><h3 id="Step-3-passwordless-login-instructions">Step 3: passwordless login instructions</h3><p><a href="https://levelup.gitconnected.com/how-to-connect-without-password-using-ssh-passwordless-9b8963c828e8">How to connect without password using SSH (passwordless)</a></p><div class="note note-secondary">            <p>Thanks for reading, if you have any questions/suggestions, please leave a comment below.</p>          </div>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>template post with syntax</title>
    <link href="/blog/2023/04/21/template-post-with-syntax/"/>
    <url>/blog/2023/04/21/template-post-with-syntax/</url>
    
    <content type="html"><![CDATA[<div class="note note-primary">            <p><a href="https://hexo.fluid-dev.com/docs/guide/">Source</a><br>This is a page that showcases all the syntax that are supported by fluid and hexo.</p>          </div><h1>Index image in home page</h1><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs markdown">---<br>title: æ–‡ç« æ ‡é¢˜<br>tags: [Hexo, Fluid]<br>index<span class="hljs-emphasis">_img: /img/example.jpg</span><br><span class="hljs-emphasis">date: 2019-10-10 10:00:00</span><br><span class="hljs-emphasis">---</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis">ä»¥ä¸‹æ˜¯æ–‡ç« å†…å®¹</span><br></code></pre></td></tr></table></figure><h1>Codeblocks</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br></code></pre></td></tr></table></figure><h1>Latex formulas</h1><p>$$<br>E=mc^2<br>$$</p><h1>Mermaid diagrams <sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Links: [Source](https://mermaid-js.github.io/mermaid/#/); [Github](https://github.com/mermaid-js/mermaid)">[1]</span></a></sup></h1><h2 id="Gannt-diagram">Gannt diagram</h2><pre><code class="mermaid" >ganttdateFormat YYYY-MM-DDtitle Adding GANTT diagram to mermaidsection A sectionCompleted task :done, des1, 2014-01-06,2014-01-08Active task :active, des2, 2014-01-09, 3dFuture task : des3, after des2, 5dFuture task2 : des4, after des3, 5d</code></pre><h2 id="classDiagram">classDiagram</h2><pre><code class=" mermaid">classDiagramClass01 &lt;|-- AveryLongClass : CoolClass03 *-- Class04Class05 o-- Class06Class07 .. Class08Class09 --&gt; C2 : Where am i?Class09 --* C3Class09 --|&gt; Class07Class07 : equals()Class07 : Object[] elementDataClass01 : size()Class01 : int chimpClass01 : int gorillaClass08 &lt;--&gt; C2: Cool label</code></pre><h2 id="Graph">Graph</h2><pre><code class=" mermaid">graph TD;    A--&gt;B;    A--&gt;C;    B--&gt;D;    C--&gt;D;</code></pre><h2 id="Sequence-diagram">Sequence diagram</h2><pre><code class=" mermaid">sequenceDiagram    participant Alice    participant Bob    Alice-&gt;&gt;John: Hello John, how are you?    loop Healthcheck        John-&gt;&gt;John: Fight against hypochondria    end    Note right of John: Rational thoughts &lt;br/&gt;prevail!    John--&gt;&gt;Alice: Great!    John-&gt;&gt;Bob: How about you?    Bob--&gt;&gt;John: Jolly good!</code></pre><h2 id="Git-graph">Git graph</h2><pre><code class=" mermaid">gitGraph   commit   commit   branch develop   checkout develop   commit   commit   checkout main   merge develop   commit   commit</code></pre><h2 id="Flowchart">Flowchart</h2><pre><code class=" mermaid">flowchart TD    A[Start] --&gt; B&#123;Is it?&#125;    B -- Yes --&gt; C[OK]    C --&gt; D[Rethink]    D --&gt; B    B -- No ----&gt; E[End]</code></pre><h1>Using footnotes</h1><p>This is a sentence<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="This is the footnote content">[2]</span></a></sup></p><p>This is a sentence<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="This is the footnote content">[2]</span></a></sup><sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="This is the footnote content">[3]</span></a></sup></p><p>This is a sentence<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="This is the footnote content">[2]</span></a></sup></p><p>This is a sentence<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="This is the footnote content">[2]</span></a></sup></p><section class="footnotes"><h1>Reference</h1><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Links: <a href="https://mermaid-js.github.io/mermaid/#/">Source</a>; <a href="https://github.com/mermaid-js/mermaid">Github</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>This is the footnote content<a href="#fnref:2" rev="footnote" class="footnote-backref"> â†©</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>This is the footnote content<a href="#fnref:3" rev="footnote" class="footnote-backref"> â†©</a></span></span></li></ol></div></section>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
